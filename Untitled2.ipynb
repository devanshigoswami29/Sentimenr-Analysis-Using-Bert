{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15886,"status":"ok","timestamp":1713415914255,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"oVZXJtYUlMks","outputId":"68cc3c35-409a-4c19-cbc3-3bee8c7e6ea1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.19.3-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.19.3-\u003etransformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2024.2.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n","Requirement already satisfied: scipy\u003e=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open\u003e=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"]}],"source":["!pip install transformers\n","!pip install gensim"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10013,"status":"ok","timestamp":1713415928450,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"6NSjDBqmlVlY"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from gensim.models import KeyedVectors\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5851,"status":"ok","timestamp":1713415939435,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"GuR-XaFulgpg"},"outputs":[],"source":["train_data = pd.read_csv('/content/drive/MyDrive/Sentiment analysis/project 2024/Dataset-20231210T071705Z-001/Dataset/train.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/Sentiment analysis/project 2024/Dataset-20231210T071705Z-001/Dataset/test.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2077,"status":"ok","timestamp":1713415945764,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"EMfSGoPql6HD"},"outputs":[],"source":["class MovieReviewDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, glove):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.glove = glove\n","\n","        self.tokenized_texts = [self.tokenizer.encode(text, add_special_tokens=True) for text in self.texts]\n","        self.input_ids = [torch.tensor(ids) for ids in self.tokenized_texts]\n","        self.attention_masks = [torch.tensor(np.where(ids \u003e 0, 1, 0)) for ids in self.tokenized_texts]\n","\n","        self.glove_vectors = [self.glove[word] if word in self.glove else np.zeros(self.glove.vector_size) for word in self.texts]\n","        self.glove_vectors = [torch.tensor(vector) for vector in self.glove_vectors]\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_ids[idx],\n","            'attention_mask': self.attention_masks[idx],\n","            'glove_vectors': self.glove_vectors[idx],\n","            'label': self.labels[idx]\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uUqbHaLG1MZ-"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-04-18 04:57:25--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2024-04-18 04:57:25--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2024-04-18 04:57:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip.1’\n","\n","glove.6B.zip.1      100%[===================\u003e] 822.24M  5.12MB/s    in 2m 40s  \n","\n","2024-04-18 05:00:06 (5.15 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["# prompt: import glove word embedding of 50d\n","\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip\n","embeddings_index = {}\n","with open('/content/glove.6B.50d.txt', encoding='utf8') as f:\n","    for line in f:\n","        word, vec = line.split(' ', 1)\n","        vec = np.fromstring(vec, sep=' ', dtype=np.float32)\n","        embeddings_index[word] = vec\n","# Extract the dimension of the word vectors\n","vector_size = len(embeddings_index[next(iter(embeddings_index))])\n","\n","# Initialize the KeyedVectors object with the correct vector_size\n","glove = KeyedVectors(embeddings_index, vector_size=vector_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1713387031023,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"sIOhrZV3mxf3","outputId":"db0da094-91aa-4c8b-8898-00d1b1ef4808"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":1202,"status":"error","timestamp":1713387064463,"user":{"displayName":"Sentiment","userId":"00820595961753594663"},"user_tz":-330},"id":"zqH1mcJnqwcT","outputId":"3bb4f0f4-3343-4c0a-93d4-f176e4e79e0e"},"outputs":[{"ename":"TypeError","evalue":"MovieReviewDataset.__init__() missing 1 required positional argument: 'glove'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-21-d73079bf36ad\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieReviewDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: MovieReviewDataset.__init__() missing 1 required positional argument: 'glove'"]}],"source":["train_dataset = MovieReviewDataset(train_data['review'].tolist(), train_data['sentiment'].tolist(), tokenizer,glove)\n","train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENtKDTb3qzMo"},"outputs":[],"source":["def train(model, dataloader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMiOQptgbPhKtYeUAgJT8FF","mount_file_id":"1Os3Y54AR1aSFgm5U3VydwSaUdeBcvU43","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}